{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Taxi V2 Q Learning",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yceqd4xYSavy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E83_Dh3KSeRB",
        "colab_type": "code",
        "outputId": "cd540e47-2d9f-4481-e6d0-2a821af5d5c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "env = gym.make(\"Taxi-v2\").env\n",
        "env.render()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|\u001b[35mR\u001b[0m:\u001b[43m \u001b[0m| : :G|\n",
            "| : : : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[34;1mB\u001b[0m: |\n",
            "+---------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmuTEhEfTXTe",
        "colab_type": "code",
        "outputId": "1003ebb6-5665-4e82-c165-0895ebcba270",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "env.reset()\n",
        "env.render()\n",
        "\n",
        "print(\"Action Space {}\".format(env.action_space))\n",
        "print(\"State Space {}\".format(env.observation_space))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : : : : |\n",
            "| : : :\u001b[43m \u001b[0m: |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "\n",
            "Action Space Discrete(6)\n",
            "State Space Discrete(500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5HvbTMKURjz",
        "colab_type": "code",
        "outputId": "1c26d678-f5e0-4cce-c59d-7a35a98639c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "state = env.encode(3,1,2,0)\n",
        "print(\"State: \", state)\n",
        "\n",
        "env.s=state\n",
        "env.render()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "State:  328\n",
            "+---------+\n",
            "|\u001b[35mR\u001b[0m: | : :G|\n",
            "| : : : : |\n",
            "| : : : : |\n",
            "| |\u001b[43m \u001b[0m: | : |\n",
            "|\u001b[34;1mY\u001b[0m| : |B: |\n",
            "+---------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoEX6dosV28E",
        "colab_type": "code",
        "outputId": "ab6646f7-298e-47bd-f183-0e47d5e9d2c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "env.P[328]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: [(1.0, 428, -1, False)],\n",
              " 1: [(1.0, 228, -1, False)],\n",
              " 2: [(1.0, 348, -1, False)],\n",
              " 3: [(1.0, 328, -1, False)],\n",
              " 4: [(1.0, 328, -10, False)],\n",
              " 5: [(1.0, 328, -10, False)]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD2aGhXA73NR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "q_table = np.zeros([env.observation_space.n, env.action_space.n])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvPKarYInmdq",
        "colab_type": "code",
        "outputId": "32c1cd8e-fbca-4380-ee89-4930b07caccc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#Training the agent\n",
        "\n",
        "import random\n",
        "from IPython.display import clear_output\n",
        "\n",
        "#Hyperparameters \n",
        "alpha = 0.05 #Learning Rate \n",
        "gamma =0.6 \n",
        "epsilon = 0.1\n",
        "\n",
        "#For plotting metrics \n",
        "\n",
        "all_epochs = []\n",
        "all_penalties = []\n",
        "\n",
        "for i in range(1,100001):\n",
        "  state = env.reset()\n",
        "  \n",
        "  epochs,penalties,rewards = 0,0,0\n",
        "  \n",
        "  done = False\n",
        "  \n",
        "  \n",
        "  while not done:\n",
        "    if random.uniform(0,1)<epsilon:\n",
        "      action = env.action_space.sample() #Explore Action Space\n",
        "      \n",
        "    else:\n",
        "      action = np.argmax(q_table[state]) #Explore Leanred Values\n",
        "      \n",
        "    next_state,reward,done,info = env.step(action)\n",
        "    \n",
        "    \n",
        "    \n",
        "    old_value = q_table[state, action]\n",
        "    next_max = np.max(q_table[next_state])\n",
        "    \n",
        "    \n",
        "    \n",
        "    new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n",
        "    q_table [state,action] = new_value\n",
        "    \n",
        "    \n",
        "    if reward == -10:\n",
        "      penalties += 1\n",
        "      \n",
        "      \n",
        "    state = next_state\n",
        "    epochs+=1\n",
        "    \n",
        "    \n",
        "  if i % 100 == 0:\n",
        "    clear_output(wait = True)\n",
        "    print(f\"Episode: {i}\")\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "print(\"Training Finished. \\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode: 100000\n",
            "Training Finished. \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwH9DMT57gz4",
        "colab_type": "code",
        "outputId": "72b8cc80-42d6-4817-efaa-fe2d0c4936bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "q_table[328]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ -2.41721894,  -2.27325184,  -2.41263294,  -2.36169301,\n",
              "       -11.30825083, -10.86891172])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "po0Vkc5i9LIM",
        "colab_type": "code",
        "outputId": "84fc19e2-456d-4687-bf53-31664d8cc9b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "\"\"\"Evaluate agent's performance after Q-learning\"\"\"\n",
        "\n",
        "total_epochs, total_penalties = 0, 0\n",
        "episodes = 100\n",
        "\n",
        "for _ in range(episodes):\n",
        "    state = env.reset()\n",
        "    epochs, penalties, reward = 0, 0, 0\n",
        "    \n",
        "    done = False\n",
        "    \n",
        "    while not done:\n",
        "        action = np.argmax(q_table[state])\n",
        "        state, reward, done, info = env.step(action)\n",
        "\n",
        "        if reward == -10:\n",
        "            penalties += 1\n",
        "\n",
        "        epochs += 1\n",
        "\n",
        "    total_penalties += penalties\n",
        "    total_epochs += epochs\n",
        "\n",
        "print(f\"Results after {episodes} episodes:\")\n",
        "print(f\"Average timesteps per episode: {total_epochs / episodes}\")\n",
        "print(f\"Average penalties per episode: {total_penalties / episodes}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results after 100 episodes:\n",
            "Average timesteps per episode: 12.61\n",
            "Average penalties per episode: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cClqvdF9TYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}